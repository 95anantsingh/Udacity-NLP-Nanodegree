{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Words\n",
    "\n",
    "Let's implement a simple function that is often used in Natural Language Processing: Counting word frequencies.\n",
    "Consider this passage of text:\n",
    "\n",
    "As I was waiting, a man came out of a side room, and at a glance I was sure he must be Long John. His left leg was cut off close by the hip, and under the left shoulder he carried a crutch, which he managed with wonderful dexterity, hopping about upon it like a bird. He was very tall and strong, with a face as big as a ham—plain and pale, but intelligent and smiling. Indeed, he seemed in the most cheerful spirits, whistling as he moved about among the tables, with a merry word or a slap on the shoulder for the more favoured of his guests.\n",
    "\n",
    "— Excerpt from Treasure Island, by Robert Louis Stevenson.\n",
    "\n",
    "In the following coding exercise, we have provided code to load the text from a file, call the function count_words() to obtain word counts (which you need to implement), and print the 10 most common and least common unique words.\n",
    "Complete the portions marked as TODO to count how many times each unique word occurs in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"Count how many times each unique word occurs in text.\"\"\"\n",
    "    counts = dict()  # dictionary of { <word>: <count> } pairs to return\n",
    "    # TODO: Convert to lowercase\n",
    "    \n",
    "    text = text.lower()\n",
    "    # TODO: Split text into tokens (words), leaving out punctuation\n",
    "    # (Hint: Use regex to split on non-alphanumeric characters)\n",
    "    \n",
    "    wlist = re.split('\\W+',text)\n",
    "    wset = list(set(wlist))\n",
    "    \n",
    "    for i in wset:\n",
    "        counts[i]=wlist.count(i)\n",
    "    \n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most common words:\n",
      "Word\tCount\n",
      "a\t9\n",
      "the\t6\n",
      "he\t6\n",
      "and\t5\n",
      "was\t4\n",
      "as\t4\n",
      "with\t3\n",
      "about\t2\n",
      "of\t2\n",
      "left\t2\n",
      "\n",
      "10 least common words:\n",
      "Word\tCount\n",
      "cut\t1\n",
      "most\t1\n",
      "spirits\t1\n",
      "among\t1\n",
      "hip\t1\n",
      "dexterity\t1\n",
      "glance\t1\n",
      "by\t1\n",
      "smiling\t1\n",
      "at\t1\n"
     ]
    }
   ],
   "source": [
    "def test_run():\n",
    "    with open(\"P02M01L01C04 input.txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "        counts = count_words(text)\n",
    "        sorted_counts = sorted(counts.items(), key=lambda pair: pair[1], reverse=True)\n",
    "        \n",
    "        print(\"10 most common words:\\nWord\\tCount\")\n",
    "        for word, count in sorted_counts[:10]:\n",
    "            print(\"{}\\t{}\".format(word, count))\n",
    "        \n",
    "        print(\"\\n10 least common words:\\nWord\\tCount\")\n",
    "        for word, count in sorted_counts[-10:]:\n",
    "            print(\"{}\\t{}\".format(word, count))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
